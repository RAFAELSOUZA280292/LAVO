import os, pickle
from typing import List, Tuple
import numpy as np
import faiss
import streamlit as st
from openai import OpenAI

# ====== VISUAL ======
st.set_page_config(page_title="LAVO - Reforma Tribut√°ria", page_icon="üìÑ", layout="centered")
st.markdown("""
<style>
    .block-container {padding-top: 2rem; max-width: 880px;}
    .login-card {padding: 1.25rem; border-radius: 16px; background: #111827; border: 1px solid #374151;}
    .login-title {font-size: 1.4rem; margin-bottom: .5rem;}
</style>
""", unsafe_allow_html=True)

# ====== CONFIG ======
EMBED_MODEL = "text-embedding-3-small"
CHAT_MODEL  = "gpt-4o-mini"

OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY", "")).strip()
client = OpenAI(api_key=OPENAI_API_KEY)

USERS = {
    "rafael souza": st.secrets.get("APP_PASS_RAFAEL", ""),
    "alex montu":   st.secrets.get("APP_PASS_ALEX",   ""),
}
INDEX_PATH = "index/faiss.index"
META_PATH  = "index/faiss_meta.pkl"

SYSTEM_PROMPT = """
Voc√™ √© a LAVO, especialista em Reforma Tribut√°ria da Lavoratory Group.
Fale SEMPRE em portugu√™s do Brasil, com precis√£o t√©cnica e did√°tica.

PERSONA E ESTILO
- Seja objetiva, clara e traga exemplos cont√°beis e fiscais pr√°ticos.
- Comporte-se como professora de cursinho (tom did√°tico), mas nunca diga isso.
- Mantenha respostas concisas, evitando jarg√µes desnecess√°rios.
- Sempre que poss√≠vel, organize em t√≥picos curtos.

PERSONALIZA√á√ÉO
- Sempre cumprimente o usu√°rio usando o NOME obtido no login (ex.: ‚ÄúOl√°, Rafael Souza!‚Äù).
- Use o nome ao longo da conversa.

ESCOPO E FONTES
- Responda SOMENTE sobre Reforma Tribut√°ria (BR).
- Baseie-se APENAS no conte√∫do fornecido pelo sistema/assistente (contexto recuperado).
- Cite somente leis, PECs, ECs, PLPs, pareceres e nomes de professores/relatores (sem links).
- Nunca mencione ‚Äúarquivos‚Äù, ‚ÄúPDFs‚Äù, ‚Äúslides‚Äù, ‚Äúmateriais de aula‚Äù, ‚Äúchunks‚Äù ou ‚Äúcontexto recuperado‚Äù.

INCERTEZA E LIMITES
- Se n√£o tiver certeza ou n√£o estiver no contexto, diga:
  ‚ÄúAinda estou estudando, mas logo aprendo e voltamos a falar.‚Äù

FORMATA√á√ÉO
- Quando fizer sentido, estruture em:
  1) Resumo r√°pido (2‚Äì4 linhas).
  2) Detalhamento pr√°tico (bullets com regras, prazos, c√°lculos e exemplos).
  3) Refer√™ncias normativas (ex.: EC 132/2023; PLP 68/2024).
- Valores: use v√≠rgula (R$ 1.000,00) e mostre a conta: 18% de R$ 1.000,00 ‚Üí R$ 180,00.
"""

# ====== FUN√á√ïES FAISS / OPENAI ======
def load_faiss_index(index_path=INDEX_PATH, meta_path=META_PATH):
    if not (os.path.exists(index_path) and os.path.exists(meta_path)):
        return None, []
    index = faiss.read_index(index_path)
    with open(meta_path, "rb") as f:
        metas = pickle.load(f)
    return index, metas

def embed_query(q: str) -> np.ndarray:
    resp = client.embeddings.create(model=EMBED_MODEL, input=[q])
    v = np.array(resp.data[0].embedding, dtype="float32")
    faiss.normalize_L2(v.reshape(1, -1))
    return v

def retrieve(index, metas, query: str, k: int = 5):
    if index is None: return []
    q = embed_query(query).reshape(1, -1)
    D, I = index.search(q, k)
    hits = []
    for pos, (idx, score) in enumerate(zip(I[0], D[0]), start=1):
        if idx < 0 or idx >= len(metas): continue
        hits.append((pos, score, metas[idx]))
    return hits

def answer_with_context(question: str, hits: List[Tuple[int, float, dict]], nome: str) -> str:
    contexto = "\n\n".join(f"[{rank}] {m['text_preview']}" for rank, score, m in hits)
    user_instruction = (
        f"Inicie a resposta cumprimentando a pessoa pelo nome exatamente assim: 'Ol√°, {nome}!'. "
        "Em seguida responda conforme o estilo e regras do sistema. "
        "Use apenas o conte√∫do abaixo como base."
    )
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user",
         "content": f"{user_instruction}\n\n<contexto>\n{contexto}\n</contexto>\n\nPergunta: {question}"},
    ]
    resp = client.chat.completions.create(
        model=CHAT_MODEL, messages=messages, temperature=0.0, max_tokens=600
    )
    return resp.choices[0].message.content

# ====== LOGIN ======
if "auth" not in st.session_state:
    st.session_state.auth = False

st.title("üßë‚Äçüè´ LAVO - Especialista em Reforma Tribut√°ria")

if not st.session_state.auth:
    with st.container():
        st.markdown('<div class="login-card">', unsafe_allow_html=True)
        st.markdown('<div class="login-title">üîí Login</div>', unsafe_allow_html=True)
        user = st.text_input("Usu√°rio (ex.: Rafael Souza)").strip()
        pwd  = st.text_input("Senha", type="password")
        if st.button("Entrar", use_container_width=True):
            key = (user or "").lower()
            if key in USERS and USERS[key] and USERS[key] == (pwd or ""):
                st.session_state.auth = True
                st.session_state.user_name = user or "Usu√°rio"
                st.success(f"Bem-vindo, {st.session_state.user_name}!")
                st.rerun()
            else:
                st.error("Usu√°rio ou senha inv√°lidos.")
        st.markdown('</div>', unsafe_allow_html=True)
    st.stop()

nome = st.session_state.get("user_name", "colega")

# ====== CARREGAR √çNDICE ======
index, metas = load_faiss_index()
if index is None:
    st.warning("‚ö†Ô∏è Nenhum √≠ndice encontrado. Gere `index/faiss.index` e `index/faiss_meta.pkl` via GitHub Actions a partir de `txts/`.")
    st.info("Ap√≥s o Actions commitar os arquivos em `index/`, atualize a p√°gina.")
    st.stop()

st.caption(f"Base carregada ‚Ä¢ trechos: {len(metas)}")

# ====== CHAT ======
if "history" not in st.session_state:
    st.session_state.history = []

for role, content in st.session_state.history:
    with st.chat_message(role):
        st.markdown(content)

q = st.chat_input("Fa√ßa sua pergunta para a LAVO‚Ä¶")
if q:
    st.session_state.history.append(("user", q))
    with st.chat_message("user"):
        st.markdown(q)

    with st.chat_message("assistant"):
        with st.spinner("Consultando‚Ä¶"):
            hits = retrieve(index, metas, q, k=5)
            ans = answer_with_context(q, hits, nome)
            st.markdown(ans)
            st.session_state.history.append(("assistant", ans))
